<?xml version="1.0" encoding="UTF-8"?><Document>
    <uima.tcas.DocumentAnnotation sofa="Sofa" begin="0" end="2931" language="en">
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="0" end="101">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="0" end="1">
                <org.apache.uima.examples.SourceDocumentInformation sofa="Sofa" begin="0" end="0" uri="file:/F:/uima-as-2.6.0-bin/apache-uima-as-2.6.0/examples/data/IB..." offsetInSource="0" documentSize="2932" lastSegment="false"/>�솮</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1" end="2">占�</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2" end="3">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="3" end="7">Life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="8" end="16">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="17" end="19">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="20" end="23">one</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="24" end="26">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="27" end="30">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="31" end="39">emerging</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="40" end="47">markets</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="48" end="50">at</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="51" end="54">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="55" end="60">heart</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="61" end="63">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="64" end="69">IBM's</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="70" end="76">growth</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="77" end="85">strategy</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="85" end="86">,</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="86" end="87">"</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="88" end="92">said</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="93" end="97">John</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="98" end="99">M</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="99" end="100">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="101" end="166">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="101" end="109">Thompson</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="109" end="110">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="111" end="114">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="115" end="121">senior</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="122" end="126">vice</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="127" end="136">president</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="137" end="138">&amp;</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="139" end="144">group</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="145" end="154">executive</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="154" end="155">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="156" end="164">Software</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="164" end="165">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="166" end="280">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="166" end="167">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="167" end="171">This</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="172" end="182">investment</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="183" end="185">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="186" end="189">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="190" end="195">first</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="196" end="198">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="199" end="200">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="201" end="207">number</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="208" end="210">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="211" end="216">steps</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="217" end="219">we</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="220" end="224">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="225" end="227">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="228" end="234">taking</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="235" end="237">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="238" end="245">advance</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="246" end="251">IBM's</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="252" end="256">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="257" end="265">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="266" end="277">initiatives</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="277" end="278">.</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="278" end="279">"</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="280" end="369">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="280" end="282">In</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="283" end="286">his</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="287" end="291">role</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="292" end="294">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="295" end="300">newly</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="301" end="310">appointed</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="311" end="326">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="311" end="314">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="315" end="326">Corporation</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="327" end="331">vice</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="332" end="340">chairman</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="340" end="341">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="342" end="351">effective</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="352" end="361">September</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="362" end="363">1</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="363" end="364">,</org.apache.uima.examples.tokenizer.Token> <example.PersonTitle sofa="Sofa" begin="365" end="368" Kind="Civilian">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="365" end="367">Mr</org.apache.uima.examples.tokenizer.Token>
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="367" end="368">.</org.apache.uima.examples.tokenizer.Token>
            </example.PersonTitle> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="369" end="504">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="369" end="377">Thompson</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="378" end="382">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="383" end="385">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="386" end="397">responsible</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="398" end="401">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="402" end="413">integrating</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="414" end="417">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="418" end="430">accelerating</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="431" end="436">IBM's</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="437" end="444">efforts</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="445" end="447">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="448" end="455">exploit</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="456" end="460">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="461" end="469">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="470" end="473">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="474" end="479">other</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="480" end="488">emerging</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="489" end="495">growth</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="496" end="501">areas</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="501" end="502">.</org.apache.uima.examples.tokenizer.Token>

</org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="504" end="636">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="504" end="507">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="508" end="517">estimates</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="518" end="521">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="522" end="528">market</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="529" end="532">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="533" end="535">IT</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="536" end="545">solutions</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="546" end="549">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="550" end="554">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="555" end="563">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="564" end="568">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="569" end="578">skyrocket</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="579" end="583">from</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="584" end="588">$3.5</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="589" end="596">billion</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="597" end="602">today</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="603" end="605">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="606" end="610">more</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="611" end="615">than</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="616" end="618">$9</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="619" end="626">billion</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="627" end="629">by</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="630" end="634">2003</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="634" end="635">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="636" end="726">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="636" end="643">Driving</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="644" end="650">demand</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="651" end="653">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="654" end="657">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="658" end="667">explosive</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="668" end="674">growth</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="675" end="677">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="678" end="685">genomic</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="685" end="686">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="687" end="696">proteomic</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="697" end="700">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="701" end="715">pharmaceutical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="716" end="724">research</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="724" end="725">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="726" end="862">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="726" end="729">For</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="730" end="737">example</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="737" end="738">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="739" end="742">the</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="743" end="764">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="743" end="748">Human</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="749" end="755">Genome</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="756" end="764">Database</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="765" end="767">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="768" end="781">approximately</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="782" end="787">three</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="788" end="797">terabytes</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="798" end="800">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="801" end="805">data</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="805" end="806">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="807" end="809">or</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="810" end="813">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="814" end="824">equivalent</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="825" end="827">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="828" end="831">150</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="832" end="839">million</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="840" end="845">pages</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="846" end="848">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="849" end="860">information</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="860" end="861">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="862" end="927">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="862" end="865">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="866" end="872">volume</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="873" end="875">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="876" end="880">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="881" end="889">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="890" end="894">data</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="895" end="897">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="898" end="906">doubling</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="907" end="912">every</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="913" end="916">six</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="917" end="923">months</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="923" end="924">.</org.apache.uima.examples.tokenizer.Token> 

</org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="927" end="1139">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="927" end="928">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="928" end="931">All</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="932" end="934">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="935" end="939">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="940" end="947">genetic</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="948" end="952">data</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="953" end="955">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="956" end="965">worthless</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="966" end="973">without</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="974" end="977">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="978" end="989">information</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="990" end="1000">technology</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1001" end="1005">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1006" end="1009">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1010" end="1014">help</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1015" end="1025">scientists</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1026" end="1032">manage</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1033" end="1036">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1037" end="1044">analyze</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1045" end="1047">it</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1048" end="1050">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1051" end="1057">unlock</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1058" end="1061">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1062" end="1070">pathways</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1071" end="1075">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1076" end="1080">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1081" end="1085">lead</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1086" end="1088">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1089" end="1092">new</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1093" end="1098">cures</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1099" end="1102">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1103" end="1107">many</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1108" end="1110">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1111" end="1118">today's</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1119" end="1127">diseases</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1127" end="1128">,</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1128" end="1129">"</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1130" end="1134">said</org.apache.uima.examples.tokenizer.Token> <example.PersonTitle sofa="Sofa" begin="1135" end="1138" Kind="Civilian">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1135" end="1137">Dr</org.apache.uima.examples.tokenizer.Token>
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1137" end="1138">.</org.apache.uima.examples.tokenizer.Token>
            </example.PersonTitle> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1139" end="1203">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1139" end="1147">Caroline</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1148" end="1153">Kovac</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1153" end="1154">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1155" end="1159">vice</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1160" end="1169">president</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1170" end="1172">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1173" end="1178">IBM's</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1179" end="1182">new</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="1183" end="1196">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1183" end="1187">Life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1188" end="1196">Sciences</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1197" end="1201">unit</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1201" end="1202">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1203" end="1312">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1203" end="1204">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1204" end="1207">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1208" end="1211">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1212" end="1216">help</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1217" end="1222">speed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1223" end="1227">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1228" end="1235">process</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1236" end="1238">by</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1239" end="1247">enabling</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1248" end="1252">more</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1253" end="1262">efficient</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1263" end="1277">interpretation</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1278" end="1280">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1281" end="1285">data</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1286" end="1289">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1290" end="1297">sharing</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1298" end="1300">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1301" end="1310">knowledge</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1310" end="1311">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1312" end="1433">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1312" end="1315">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1316" end="1325">potential</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1326" end="1329">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1330" end="1336">change</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1337" end="1342">based</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1343" end="1345">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1346" end="1356">innovation</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1357" end="1359">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1360" end="1364">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1365" end="1373">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1374" end="1376">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1377" end="1383">bigger</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1384" end="1388">than</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1389" end="1392">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1393" end="1399">change</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1400" end="1406">caused</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1407" end="1409">by</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1410" end="1413">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1414" end="1421">digital</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1422" end="1429">circuit</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1429" end="1430">.</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1430" end="1431">"</org.apache.uima.examples.tokenizer.Token>

</org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1433" end="1715">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1433" end="1438">Among</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1439" end="1442">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1443" end="1447">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1448" end="1456">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1457" end="1468">initiatives</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1469" end="1476">already</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1477" end="1485">underway</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1486" end="1488">at</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1489" end="1492">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1493" end="1496">are</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1496" end="1497">:</org.apache.uima.examples.tokenizer.Token>
<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1498" end="1499">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1500" end="1513">DiscoveryLink</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1513" end="1514">*</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1515" end="1516">-</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1516" end="1517">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1518" end="1521">For</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1522" end="1525">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1526" end="1531">first</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1532" end="1536">time</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1536" end="1537">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1538" end="1549">researchers</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1550" end="1555">using</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1556" end="1560">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1561" end="1572">combination</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1573" end="1575">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1576" end="1586">innovative</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1587" end="1597">middleware</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1598" end="1601">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1602" end="1613">integration</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1614" end="1622">services</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1623" end="1626">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1627" end="1631">join</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1632" end="1640">together</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1641" end="1652">information</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1653" end="1657">from</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1658" end="1662">many</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1663" end="1670">sources</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1671" end="1673">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1674" end="1679">solve</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1680" end="1687">complex</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1688" end="1695">medical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1696" end="1704">research</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1705" end="1713">problems</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1713" end="1714">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1715" end="1875">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1715" end="1728">DiscoveryLink</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1729" end="1736">creates</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1737" end="1738">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1739" end="1740">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1740" end="1747">virtual</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1748" end="1756">database</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1756" end="1757">"</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1758" end="1762">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1763" end="1770">permits</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1771" end="1775">data</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1776" end="1778">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1779" end="1781">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1782" end="1790">accessed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1791" end="1794">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1795" end="1804">extracted</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1805" end="1809">from</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1810" end="1818">multiple</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1819" end="1823">data</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1824" end="1831">sources</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1832" end="1836">used</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1837" end="1839">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1840" end="1848">research</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1849" end="1852">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1853" end="1864">development</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1865" end="1873">projects</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1873" end="1874">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1875" end="2024">
            <example.Name sofa="Sofa" begin="1875" end="1882">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1875" end="1879">This</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1880" end="1882">IT</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1883" end="1891">solution</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1892" end="1895">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1896" end="1908">dramatically</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1909" end="1916">improve</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1917" end="1924">product</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1925" end="1930">cycle</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1931" end="1935">time</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1936" end="1939">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1940" end="1945">lower</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1946" end="1957">development</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1958" end="1963">costs</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1964" end="1967">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1968" end="1982">pharmaceutical</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1982" end="1983">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1984" end="1997">biotechnology</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1998" end="2001">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2002" end="2014">agri-science</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2015" end="2024">companies</org.apache.uima.examples.tokenizer.Token>
        </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2024" end="2025">
            <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="2024" end="2025">.</org.apache.uima.examples.tokenizer.Sentence>
        </org.apache.uima.examples.tokenizer.Token>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="2025" end="2237"> 

<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2028" end="2029">-</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="2030" end="2039">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2030" end="2034">Blue</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2035" end="2039">Gene</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2039" end="2040">*</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2041" end="2042">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2043" end="2046">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2047" end="2049">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2050" end="2058">building</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2059" end="2060">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2061" end="2074">supercomputer</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2075" end="2078">100</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2079" end="2084">times</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2085" end="2091">faster</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2092" end="2096">than</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2097" end="2100">any</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2101" end="2110">available</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2111" end="2116">today</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2117" end="2125">designed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2126" end="2128">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2129" end="2136">advance</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2137" end="2150">understanding</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2151" end="2153">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2154" end="2157">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2158" end="2168">mechanisms</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2169" end="2175">behind</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2176" end="2183">protein</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2184" end="2191">folding</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2192" end="2199">through</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2200" end="2211">large-scale</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2212" end="2224">biomolecular</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2225" end="2235">simulation</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2235" end="2236">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="2237" end="2863">
            <example.Name sofa="Sofa" begin="2237" end="2248">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2237" end="2239">In</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2240" end="2248">December</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2248" end="2249">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2250" end="2253">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2254" end="2263">committed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2264" end="2268">$100</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2269" end="2276">million</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2277" end="2279">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2280" end="2284">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2285" end="2294">five-year</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2295" end="2303">research</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2304" end="2311">project</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2312" end="2314">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2315" end="2322">advance</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2323" end="2326">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2327" end="2343">state-of-the-art</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2344" end="2346">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2347" end="2361">supercomputing</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2362" end="2365">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2366" end="2376">biological</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2377" end="2389">applications</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2389" end="2390">.</org.apache.uima.examples.tokenizer.Token>
<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2391" end="2392">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2393" end="2407">Bio-Dictionary</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2407" end="2408">*</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2409" end="2410">-</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2410" end="2411">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2412" end="2415">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2416" end="2419">has</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2420" end="2428">compiled</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2429" end="2430">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2431" end="2438">protein</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2439" end="2449">dictionary</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2450" end="2460">containing</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2461" end="2465">some</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2466" end="2468">30</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2469" end="2476">million</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2477" end="2484">protein</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2485" end="2486">"</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2486" end="2491">words</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2491" end="2492">"</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2493" end="2501">designed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2502" end="2504">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2505" end="2515">accelerate</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2516" end="2519">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2520" end="2533">understanding</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2534" end="2536">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2537" end="2544">protein</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2545" end="2551">shapes</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2552" end="2555">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2556" end="2582">functions.Bio-Dictionaries</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2583" end="2586">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2587" end="2595">selected</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2596" end="2603">genomes</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2603" end="2604">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2605" end="2607">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2608" end="2612">well</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2613" end="2615">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2616" end="2630">bioinformatics</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2631" end="2641">algorithms</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2642" end="2645">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2646" end="2653">pattern</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2654" end="2663">discovery</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2664" end="2667">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2668" end="2673">other</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2674" end="2682">relevant</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2683" end="2695">applications</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2695" end="2696">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2697" end="2700">are</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2701" end="2710">available</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2711" end="2713">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2714" end="2724">scientists</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2725" end="2728">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2729" end="2740">researchers</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2741" end="2744">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2745" end="2758">noncommercial</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2759" end="2762">use</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2763" end="2770">through</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2771" end="2772">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2773" end="2780">website</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2781" end="2790">dedicated</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2791" end="2793">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2794" end="2798">life</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2799" end="2807">sciences</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2808" end="2815">content</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2816" end="2818">at</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2819" end="2823">http</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2823" end="2824">:</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2824" end="2825">/</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2825" end="2826">/</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2826" end="2846">www.research.ibm.com</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2846" end="2847">/</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2847" end="2854">compsci</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2854" end="2855">/</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2855" end="2862">compbio</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2862" end="2863">/</org.apache.uima.examples.tokenizer.Token>
        </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2863" end="2864">
            <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="2863" end="2864">.</org.apache.uima.examples.tokenizer.Sentence>
        </org.apache.uima.examples.tokenizer.Token>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="2864" end="2931">

<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2866" end="2867">*</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2868" end="2877">Indicates</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2878" end="2887">trademark</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2888" end="2890">or</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2891" end="2901">registered</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2902" end="2911">trademark</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2912" end="2914">of</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="2915" end="2930">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2915" end="2918">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2919" end="2930">Corporation</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="2930" end="2931">.</org.apache.uima.examples.tokenizer.Token>
        </org.apache.uima.examples.tokenizer.Sentence>
    </uima.tcas.DocumentAnnotation>
</Document>
