<?xml version="1.0" encoding="UTF-8"?><Document>
    <uima.tcas.DocumentAnnotation sofa="Sofa" begin="0" end="1588" language="en">
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="0" end="447">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="0" end="1">
                <org.apache.uima.examples.SourceDocumentInformation sofa="Sofa" begin="0" end="0" uri="file:/F:/uima-as-2.6.0-bin/apache-uima-as-2.6.0/examples/data/Tr..." offsetInSource="0" documentSize="1590" lastSegment="false"/>�솮</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1" end="12">�뮒dventurous</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="13" end="43">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="13" end="21">Research</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="22" end="28">Summer</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="29" end="36">Seminar</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="37" end="43">Series</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="44" end="45">-</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="46" end="86">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="46" end="55">Trainable</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="56" end="67">Information</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="68" end="78">Extraction</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="79" end="86">Systems</org.apache.uima.examples.tokenizer.Token>
            </example.Name>

<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="88" end="94">August</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="95" end="97">19</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="97" end="98">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="99" end="103">2003</org.apache.uima.examples.tokenizer.Token>   <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="106" end="108">02</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="108" end="109">:</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="109" end="111">00</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="112" end="114">PM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="115" end="116">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="117" end="119">03</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="119" end="120">:</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="120" end="122">30</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="123" end="125">PM</org.apache.uima.examples.tokenizer.Token>  
<example.Name sofa="Sofa" begin="128" end="141">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="128" end="133">David</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="134" end="141">Johnson</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="141" end="142">,</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="143" end="153">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="143" end="148">Frank</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="149" end="153">Oles</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="153" end="154">,</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="155" end="165">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="155" end="159">Tong</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="160" end="165">Zhang</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="165" end="166">(</org.apache.uima.examples.tokenizer.Token>
            <example.Name sofa="Sofa" begin="166" end="178">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="166" end="169">IBM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="170" end="178">Research</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="178" end="179">)</org.apache.uima.examples.tokenizer.Token>    
<example.Name sofa="Sofa" begin="184" end="196">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="184" end="193">Hawthorne</org.apache.uima.examples.tokenizer.Token> GN</example.Name>-F15 
<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="202" end="214">Availability</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="214" end="215">:</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="216" end="220">Open</org.apache.uima.examples.tokenizer.Token>  

<org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="224" end="227">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="228" end="237">technical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="238" end="247">objective</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="248" end="250">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="251" end="254">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="255" end="259">TIES</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="260" end="267">project</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="268" end="270">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="271" end="273">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="274" end="279">build</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="280" end="292">customizable</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="293" end="300">systems</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="301" end="305">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="306" end="309">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="310" end="318">identify</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="319" end="324">named</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="325" end="333">entities</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="334" end="336">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="337" end="341">text</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="341" end="342">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="343" end="347">such</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="348" end="350">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="351" end="358">persons</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="358" end="359">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="360" end="373">organizations</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="373" end="374">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="375" end="378">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="379" end="388">locations</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="388" end="389">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="390" end="392">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="393" end="397">well</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="398" end="400">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="401" end="412">identifying</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="413" end="422">relations</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="423" end="430">between</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="431" end="436">those</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="437" end="445">entities</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="445" end="446">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="447" end="580">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="447" end="450">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="451" end="460">technical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="461" end="469">approach</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="470" end="472">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="473" end="475">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="476" end="483">develop</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="484" end="487">new</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="488" end="499">statistical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="500" end="503">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="504" end="512">symbolic</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="513" end="520">machine</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="521" end="529">learning</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="530" end="540">algorithms</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="541" end="543">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="544" end="551">service</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="552" end="554">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="555" end="558">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="559" end="568">technical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="569" end="578">objective</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="578" end="579">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="580" end="652">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="580" end="584">Also</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="584" end="585">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="586" end="588">we</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="589" end="592">are</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="593" end="600">working</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="601" end="603">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="604" end="613">combining</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="614" end="625">statistical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="626" end="630">with</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="631" end="639">symbolic</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="640" end="650">techniques</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="650" end="651">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="652" end="699">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="652" end="655">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="656" end="661">first</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="662" end="666">part</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="667" end="669">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="670" end="674">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="675" end="679">talk</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="679" end="680">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="681" end="686">given</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="687" end="689">by</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="690" end="695">David</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="696" end="697">E</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="697" end="698">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="699" end="774">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="699" end="706">Johnson</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="706" end="707">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="708" end="712">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="713" end="720">provide</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="721" end="722">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="723" end="730">general</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="731" end="739">overview</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="740" end="742">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="743" end="746">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="747" end="752">goals</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="753" end="755">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="756" end="759">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="760" end="764">TIES</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="765" end="772">project</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="772" end="773">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="774" end="901">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="774" end="777">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="778" end="784">second</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="785" end="789">part</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="789" end="790">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="791" end="796">given</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="797" end="799">by</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="800" end="810">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="800" end="804">Tong</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="805" end="810">Zhang</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="810" end="811">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="812" end="816">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="817" end="824">provide</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="825" end="835">background</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="836" end="838">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="839" end="847">applying</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="848" end="859">statistical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="860" end="867">machine</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="868" end="876">learning</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="877" end="879">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="880" end="884">this</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="885" end="892">problem</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="893" end="899">domain</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="899" end="900">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="901" end="1016">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="901" end="905">Tong</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="906" end="910">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="911" end="915">also</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="916" end="924">describe</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="925" end="928">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="929" end="939">particular</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="940" end="951">statistical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="952" end="960">approach</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="961" end="966">taken</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="966" end="967">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="968" end="973">which</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="974" end="976">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="977" end="983">termed</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="984" end="1008">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="984" end="990">Robust</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="991" end="995">Risk</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="996" end="1008">Minimization</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1009" end="1010">(</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1010" end="1013">RMM</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1013" end="1014">)</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1014" end="1015">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1016" end="1057">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1016" end="1019">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1020" end="1025">final</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1026" end="1030">part</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1031" end="1035">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1036" end="1038">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1039" end="1044">given</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1045" end="1047">by</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1048" end="1053">Frank</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1054" end="1055">J</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1055" end="1056">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1057" end="1063">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1057" end="1061">Oles</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1061" end="1062">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1063" end="1129">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1063" end="1068">Frank</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1069" end="1073">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1074" end="1083">introduce</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1084" end="1087">his</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1088" end="1094">theory</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1095" end="1097">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1098" end="1118">precedence-inclusion</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1119" end="1127">patterns</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1127" end="1128">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1129" end="1333">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1129" end="1149">Precedence-inclusion</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1150" end="1158">patterns</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1159" end="1162">are</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1163" end="1175">mathematical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1176" end="1186">structures</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1187" end="1197">possessing</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1198" end="1206">multiple</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1207" end="1218">interacting</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1219" end="1225">strict</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1226" end="1233">partial</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1234" end="1240">orders</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1241" end="1245">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1246" end="1253">satisfy</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1254" end="1260">axioms</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1261" end="1273">generalizing</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1274" end="1277">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1278" end="1286">familiar</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1287" end="1297">properties</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1298" end="1300">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1301" end="1314">irreflexivity</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1315" end="1318">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1319" end="1331">transitivity</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1331" end="1332">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1333" end="1588">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1333" end="1337">This</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1338" end="1342">very</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1343" end="1350">general</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1351" end="1357">theory</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1358" end="1366">provides</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1367" end="1368">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1369" end="1378">radically</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1379" end="1382">new</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1383" end="1391">approach</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1392" end="1394">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1395" end="1403">symbolic</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1403" end="1404">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1405" end="1407">as</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1408" end="1415">opposed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1416" end="1418">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1419" end="1430">statistical</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1430" end="1431">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1432" end="1439">pattern</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1440" end="1454">generalization</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1455" end="1459">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1460" end="1463">can</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1464" end="1466">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1467" end="1474">applied</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1475" end="1477">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1478" end="1488">relational</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1489" end="1497">learning</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1498" end="1500">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1501" end="1502">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1503" end="1509">number</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1510" end="1512">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1513" end="1521">settings</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1521" end="1522">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1523" end="1532">including</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1533" end="1541">learning</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1542" end="1547">based</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1548" end="1550">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1551" end="1555">text</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1555" end="1556">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1557" end="1559">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1560" end="1566">images</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1566" end="1567">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1568" end="1570">or</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1571" end="1573">on</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1574" end="1580">videos</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1580" end="1581">.</org.apache.uima.examples.tokenizer.Token> 
 

 
</org.apache.uima.examples.tokenizer.Sentence>
    </uima.tcas.DocumentAnnotation>
</Document>
