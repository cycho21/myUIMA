<?xml version="1.0" encoding="UTF-8"?><Document>
    <uima.tcas.DocumentAnnotation sofa="Sofa" begin="0" end="1485" language="en">
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="0" end="506">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="0" end="1">
                <org.apache.uima.examples.SourceDocumentInformation sofa="Sofa" begin="0" end="0" uri="file:/F:/uima-as-2.6.0-bin/apache-uima-as-2.6.0/examples/data/Se..." offsetInSource="0" documentSize="1490" lastSegment="false"/>�솮</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1" end="4">�뮩IT</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="5" end="12">Seminar</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="12" end="13">:</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="14" end="24">Challenges</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="25" end="27">in</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="28" end="46">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="28" end="34">Speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="35" end="46">Recognition</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="49" end="55">August</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="56" end="57">8</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="57" end="58">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="59" end="63">2003</org.apache.uima.examples.tokenizer.Token>   <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="66" end="68">10</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="68" end="69">:</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="69" end="71">30</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="72" end="74">AM</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="75" end="76">-</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="77" end="79">11</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="79" end="80">:</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="80" end="82">30</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="83" end="85">AM</org.apache.uima.examples.tokenizer.Token> 
  <example.Name sofa="Sofa" begin="89" end="105">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="89" end="97">Lawrence</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="98" end="105">Rabiner</org.apache.uima.examples.tokenizer.Token>
            </example.Name> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="106" end="107">,</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="108" end="131">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="108" end="117">Associate</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="118" end="126">Director</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="127" end="131">CAIP</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="131" end="132">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="133" end="140">Rutgers</org.apache.uima.examples.tokenizer.Token> 
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="144" end="154">University</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="154" end="155">,</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="156" end="170">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="156" end="165">Professor</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="166" end="170">Univ</org.apache.uima.examples.tokenizer.Token>
            </example.Name>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="170" end="171">.</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="172" end="174">of</org.apache.uima.examples.tokenizer.Token> <example.Name sofa="Sofa" begin="175" end="188">
                <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="175" end="180">Santa</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="181" end="188">Barbara</org.apache.uima.examples.tokenizer.Token>
            </example.Name>   
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="194" end="202">Yorktown</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="203" end="205">20</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="205" end="206">-</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="206" end="209">043</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="212" end="224">Availability</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="224" end="225">:</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="226" end="230">Open</org.apache.uima.examples.tokenizer.Token> 

  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="235" end="241">Speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="242" end="253">recognition</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="254" end="257">has</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="258" end="265">matured</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="266" end="268">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="269" end="272">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="273" end="278">point</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="279" end="284">where</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="285" end="287">it</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="290" end="292">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="293" end="296">now</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="297" end="302">being</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="303" end="309">widely</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="310" end="317">applied</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="318" end="320">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="321" end="322">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="323" end="328">range</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="329" end="331">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="332" end="344">applications</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="347" end="356">including</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="357" end="364">desktop</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="365" end="374">dictation</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="374" end="375">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="376" end="380">cell</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="381" end="386">phone</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="387" end="391">name</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="392" end="399">dialing</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="399" end="400">,</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="403" end="408">agent</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="409" end="419">technology</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="419" end="420">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="421" end="430">automated</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="431" end="439">operator</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="440" end="448">services</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="448" end="449">,</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="452" end="462">telematics</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="462" end="463">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="464" end="468">call</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="469" end="475">center</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="476" end="486">automation</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="487" end="490">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="491" end="495">help</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="496" end="501">desks</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="501" end="502">.</org.apache.uima.examples.tokenizer.Token>

  </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="506" end="810">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="506" end="514">Although</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="515" end="518">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="519" end="529">technology</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="530" end="532">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="533" end="538">often</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="539" end="543">good</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="544" end="550">enough</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="551" end="554">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="555" end="559">many</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="562" end="564">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="565" end="570">these</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="571" end="583">applications</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="583" end="584">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="585" end="590">there</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="591" end="597">remain</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="598" end="601">key</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="602" end="612">challenges</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="613" end="615">in</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="618" end="627">virtually</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="628" end="633">every</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="634" end="640">aspect</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="641" end="643">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="644" end="650">speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="651" end="662">recognition</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="663" end="667">that</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="670" end="677">prevent</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="678" end="681">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="682" end="692">technology</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="693" end="697">from</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="698" end="703">being</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="704" end="708">used</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="709" end="721">ubiquitously</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="722" end="724">in</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="727" end="730">any</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="731" end="742">environment</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="742" end="743">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="744" end="747">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="748" end="751">any</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="752" end="759">speaker</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="759" end="760">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="761" end="764">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="765" end="768">for</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="769" end="771">an</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="772" end="776">even</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="779" end="786">broader</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="787" end="792">range</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="793" end="795">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="796" end="808">applications</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="808" end="809">.</org.apache.uima.examples.tokenizer.Token> </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="810" end="1204">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="810" end="814">This</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="815" end="819">talk</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="820" end="824">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="825" end="832">analyze</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="835" end="838">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="839" end="840">占�</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="840" end="846">�걪peech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="847" end="853">Circle</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="853" end="854">占�</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="854" end="855">占�</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="856" end="860">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="861" end="868">enables</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="869" end="870">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="871" end="877">person</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="878" end="880">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="881" end="889">maintain</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="892" end="893">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="894" end="900">dialog</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="901" end="905">with</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="906" end="907">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="908" end="915">machine</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="916" end="921">using</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="922" end="928">speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="929" end="940">recognition</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="940" end="941">,</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="944" end="950">spoken</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="951" end="959">language</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="960" end="973">understanding</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="973" end="974">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="975" end="981">dialog</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="982" end="992">management</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="993" end="996">and</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="999" end="1005">spoken</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1006" end="1014">language</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1015" end="1025">generation</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1025" end="1026">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1027" end="1030">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1031" end="1038">finally</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1039" end="1053">text-to-speech</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1056" end="1065">synthesis</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1065" end="1066">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1067" end="1070">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1071" end="1075">show</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1076" end="1081">where</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1082" end="1093">significant</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1094" end="1102">progress</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1103" end="1106">has</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1109" end="1113">been</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1114" end="1118">made</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1118" end="1119">,</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1120" end="1123">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1124" end="1129">where</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1130" end="1135">there</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1136" end="1142">remain</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1143" end="1151">critical</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1152" end="1160">problems</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1163" end="1167">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1168" end="1172">need</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1173" end="1175">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1176" end="1178">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1179" end="1188">addressed</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1189" end="1192">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1193" end="1199">solved</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1199" end="1200">.</org.apache.uima.examples.tokenizer.Token>

  </org.apache.uima.examples.tokenizer.Sentence>
        <org.apache.uima.examples.tokenizer.Sentence sofa="Sofa" begin="1204" end="1485">
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1204" end="1207">The</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1208" end="1212">talk</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1213" end="1217">will</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1218" end="1225">include</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1226" end="1233">several</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1234" end="1239">audio</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1240" end="1243">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1244" end="1249">video</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1250" end="1258">examples</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1261" end="1263">of</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1264" end="1270">speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1271" end="1282">recognition</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1283" end="1286">and</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1287" end="1293">speech</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1294" end="1307">understanding</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1308" end="1315">systems</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1318" end="1322">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1323" end="1327">have</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1328" end="1332">been</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1333" end="1340">studied</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1341" end="1343">in</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1344" end="1347">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1348" end="1358">laboratory</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1359" end="1361">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1362" end="1372">illustrate</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1375" end="1378">the</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1379" end="1389">challenges</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1390" end="1394">that</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1395" end="1401">remain</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1402" end="1404">to</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1405" end="1407">be</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1408" end="1414">solved</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1415" end="1421">before</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1422" end="1428">speech</org.apache.uima.examples.tokenizer.Token>
  <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1431" end="1442">recognition</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1443" end="1445">is</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1446" end="1456">considered</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1457" end="1458">a</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1459" end="1465">solved</org.apache.uima.examples.tokenizer.Token> <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1466" end="1473">problem</org.apache.uima.examples.tokenizer.Token>
            <org.apache.uima.examples.tokenizer.Token sofa="Sofa" begin="1473" end="1474">.</org.apache.uima.examples.tokenizer.Token> 

       
</org.apache.uima.examples.tokenizer.Sentence>
    </uima.tcas.DocumentAnnotation>
</Document>
